{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Machine Translation\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we will build a deep neural network that functions as part of an end-to-end machine translation pipeline. The completed pipeline will accept french text as input and return the english translation.\n",
    "\n",
    "__Proposed Approach__\n",
    "\n",
    "- Preprocessing: Load and examine data, cleaning, tokenization, padding\n",
    "- Modeling: Build an encoder-decoder model with Attention\n",
    "- Prediction: Generate specific translations of French to English, and compare the output translations to the ground truth translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "\n",
    "import os, sys\n",
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, GRU, Dense, Embedding, \\\n",
    "  Bidirectional, RepeatVector, Concatenate, Activation, Dot, Lambda\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import adam\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "% matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 30\n",
    "LATENT_DIM = 256\n",
    "LATENT_DIM_DECODER = 256 \n",
    "EMBEDDING_DIM = 300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We begin by investigating the dataset that will be used to train and evaluate your pipeline.  \n",
    "\n",
    "### Load Data\n",
    "The `data_en` file contains English sentences with their French translations in the `data_fr` file. Load the English and French data from these files from running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample translations (137860)\n",
      "( 0 ) FR:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "\n",
      "( 0 ) EN:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "\n",
      "( 1 ) FR:  les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
      "\n",
      "( 1 ) EN:  the united states is usually chilly during july , and it is usually freezing in november .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "french_sentences = []\n",
    "english_sentences = []\n",
    "\n",
    "test_source_sent = []\n",
    "test_target_sent = []\n",
    "\n",
    "#Read files from folder\n",
    "with open('data_fr', encoding='utf-8') as f:\n",
    "    for l_i, line in enumerate(f):\n",
    "        french_sentences.append(line)\n",
    "        \n",
    "        \n",
    "            \n",
    "with open('data_en', encoding='utf-8') as f:\n",
    "    for l_i, line in enumerate(f):\n",
    "        english_sentences.append(line)      \n",
    "        \n",
    "#Calculate the dataset size            \n",
    "assert len(french_sentences)==len(english_sentences),'Source: %d, Target: %d'%(len(french_sentences),len(english_sentences))\n",
    "\n",
    "df=pd.DataFrame(french_sentences,columns=['fra'])\n",
    "df['eng']=english_sentences\n",
    "df=df[0:50000]\n",
    "print('Sample translations (%d)'%len(french_sentences))\n",
    "for i in range(0,2):\n",
    "    print('(',i,') FR: ', df.iloc[i,0])\n",
    "    print('(',i,') EN: ', df.iloc[i,1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_train, fr_test, en_train, en_test = train_test_split(df[\"fra\"],df[\"eng\"], test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample train size: 40000\n"
     ]
    }
   ],
   "source": [
    "input_texts = [] # French sentences\n",
    "target_texts = [] # English sentences\n",
    "target_texts_inputs = []# english sentences offset by 1 for teacher forcing\n",
    "\n",
    "#Converting to lowercase\n",
    "fr_train=[line.lower() for line in fr_train]\n",
    "en_train=[line.lower() for line in en_train]\n",
    "NUM_SAMPLES=len(fr_train)\n",
    "print(\"Sample train size:\",NUM_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the sentences, you can see that they have been preprocessed already.  The puncuations have been delimited using spaces. All the text have been converted to lowercase.  This should save you some time, but the text requires more preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "For this project, you won't use text data as input to your model. Instead, you'll convert the text into sequences of integers using the following preprocess methods:\n",
    "1. Add start and end tokens to the sentences\n",
    "2. Tokenize the words of the sentences\n",
    "3. Add padding to make all the sequences of same length.\n",
    "\n",
    "Time to start preprocessing the data...\n",
    "### Tokenize \n",
    "For a neural network to predict on text data, it first has to be turned into data it can understand. Text data like \"dog\" is a sequence of ASCII character encodings.  Since a neural network is a series of multiplication and addition operations, the input data needs to be number(s).\n",
    "\n",
    "We can turn each character into a number or each word into a number.  These are called character and word ids, respectively.  Character ids are used for character level models that generate text predictions for each character.  A word level model uses word ids that generate text predictions for each word.  Word level models tend to learn better, since they are lower in complexity, so we'll use those.\n",
    "\n",
    "Turn each sentence into a sequence of words ids using Keras's [`Tokenizer`](https://keras.io/preprocessing/text/#tokenizer) function. Use this function to tokenize `english_sentences` and `french_sentences` in the cell below.\n",
    "\n",
    "\n",
    "### Padding\n",
    "When batching the sequence of word ids together, each sequence needs to be the same length. Since sentences are dynamic in length, we can add padding to the end of the sequences to make them the same length.\n",
    "\n",
    "Make sure all the English sequences have the same length and all the French sequences have the same length by adding padding to the end of each sequence using Keras's [`pad_sequences`](https://keras.io/preprocessing/sequence/#pad_sequences) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Preprocess Train Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding <sos> and <eos> tokens\n",
    "\n",
    "for lines in en_train:\n",
    "    target_texts_inputs.append('<sos>'+\" \"+ lines)\n",
    "    \n",
    "for lines in en_train:\n",
    "    target_texts.append(lines+ \" \" +'<eos>')\n",
    "    \n",
    "for lines in fr_train:\n",
    "    input_texts.append(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n",
      "Max train English sentence length: 18\n",
      "Max train French sentence length: 20\n"
     ]
    }
   ],
   "source": [
    "# tokenize French sentences\n",
    "tokenizer_inputs = Tokenizer()\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)\n",
    "\n",
    "# word to index mapping for French\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "\n",
    "# Max length of French sentence\n",
    "max_len_input = max(len(s) for s in input_sequences)\n",
    "\n",
    "#tokenize English sentences\n",
    "tokenizer_outputs = Tokenizer(filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs) \n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)\n",
    "\n",
    "# Word to index mapping for English\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "\n",
    "# store number of output words for later\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "\n",
    "# Max length of English sentence\n",
    "max_len_target = max(len(s) for s in target_sequences)\n",
    "\n",
    "# pad the sequences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)\n",
    "decoder_inputs = pad_sequences(target_sequences_inputs, maxlen=max_len_target, padding='post')\n",
    "decoder_targets = pad_sequences(target_sequences, maxlen=max_len_target, padding='post')\n",
    "\n",
    "print('Data Preprocessed')\n",
    "print(\"Max train English sentence length:\", max_len_target)\n",
    "print(\"Max train French sentence length:\", max_len_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Preprocess Test Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test Preparation\n",
    "input_texts_test = [] # French sentences\n",
    "target_texts_test = [] # English sentences\n",
    "target_texts_inputs_test = []# english sentences offset by 1 for teacher forcing\n",
    "\n",
    "#Converting to lowercase\n",
    "fr_test=[line.lower() for line in fr_test]\n",
    "en_test=[line.lower() for line in en_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding <sos> and <eos> tokens\n",
    "\n",
    "for lines in en_test:\n",
    "    target_texts_inputs_test.append('<sos>'+\" \"+ lines)\n",
    "    \n",
    "for lines in en_test:\n",
    "    target_texts_test.append(lines+ \" \" +'<eos>')\n",
    "    \n",
    "for lines in fr_test:\n",
    "    input_texts_test.append(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max test English sentence length: 18\n",
      "Max test French sentence length: 20\n"
     ]
    }
   ],
   "source": [
    "# tokenize French sentences\n",
    "\n",
    "input_sequences_test = tokenizer_inputs.texts_to_sequences(input_texts_test)\n",
    "\n",
    "\n",
    "target_sequences_test = tokenizer_outputs.texts_to_sequences(target_texts_test)\n",
    "target_sequences_inputs_test = tokenizer_outputs.texts_to_sequences(target_texts_inputs_test)\n",
    "\n",
    "# pad the sequences\n",
    "encoder_inputs_test = pad_sequences(input_sequences_test, maxlen=max_len_input)\n",
    "decoder_inputs_test = pad_sequences(target_sequences_inputs_test, maxlen=max_len_target, padding='post')\n",
    "decoder_targets_test = pad_sequences(target_sequences_test, maxlen=max_len_target, padding='post')\n",
    "\n",
    "print(\"Max test English sentence length:\", decoder_inputs_test.shape[1])\n",
    "print(\"Max test French sentence length:\", encoder_inputs_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "\n",
    "In word embeddings, every word is represented as an n-dimensional dense vector. The words that are similar will have similar vector. The position of a word within the vector space is learned from text and is based on the words that surround the word when it is used.\n",
    "\n",
    "For French sentences, i.e. the inputs, we will use the [`GloVe`](https://nlp.stanford.edu/projects/glove/) word embeddings. For the translated English sentences in the output, we will use custom word embeddings.\n",
    "\n",
    "Let's create word embeddings for the inputs first. To do so, we need to load the GloVe word vectors into memory. We will then create a dictionary where words are the keys and the corresponding vectors are values, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#Load pretrained word vectors from Glove\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(os.path.join('glove.6B.%sd.txt' % EMBEDDING_DIM), encoding=\"utf8\") as f:\n",
    "  # is just a space-separated text file in the format:\n",
    "  # word vec[0] vec[1] vec[2] ...\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words=len(word2idx_inputs) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "  if i < num_words:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model\n",
    "The idea is to have two recurrent neural networks (RNNs) with an encoder-decoder architecture: read the input words one by one to obtain a vector representation of a fixed dimensionality (encoder), and, conditioned on these inputs, extract the output words one by one using another RNN (decoder).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Softmax Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_over_time(x):\n",
    "  assert(K.ndim(x) > 2)\n",
    "  e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
    "  s = K.sum(e, axis=1, keepdims=True)\n",
    "  return e / s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embedding layer\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  input_length=max_len_input,\n",
    "  # trainable=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding\n",
    "\n",
    "To make predictions, the final layer of the model will be a dense layer, therefore we need the outputs in the form of one-hot encoded vectors, since we will be using softmax activation function at the dense layer. To create such one-hot encoded output, the next step is to assign 1 to the column number that corresponds to the integer representation of the word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decoder_targets_one_hot = np.zeros(\n",
    "  (\n",
    "    len(input_texts),\n",
    "    max_len_target,\n",
    "    num_words_output\n",
    "  ),\n",
    "  dtype='float32'\n",
    ")\n",
    "\n",
    "# assign the values\n",
    "for i, d in enumerate(decoder_targets):\n",
    "  for t, word in enumerate(d):\n",
    "    decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Encoding Layer\n",
    "The input to the encoder will be the sentence in French and the output will be the hidden state and cell state of the LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = Bidirectional(LSTM(\n",
    "  LATENT_DIM,\n",
    "  return_sequences=True,\n",
    "))\n",
    "encoder_outputs = encoder(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Decoder Layer\n",
    "\n",
    "The next step is to define the decoder. The decoder will have two inputs: the hidden state and cell state from the encoder and the input sentence, which actually will be the output sentence with an \"</sos/>\" token appended at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_target,))\n",
    "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Attention Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the performance of the Neural Machine Translator, Attention mechanism (Dot attention) is implemented. The attention model develops a context vector that is filtered specifically for each output time step.\n",
    "\n",
    "Attention places different focus on different words by assigning each word with a score. Then, using the softmaxed scores, we aggregate the encoder hidden states using a weighted sum of the encoder hidden states, to get the context vector. \n",
    "\n",
    "Rather than re-iterating through the equations for calculating attention, a function `one_step_attention` is defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention\n",
    "attn_repeat_layer = RepeatVector(max_len_input)\n",
    "attn_concat_layer = Concatenate(axis=-1)\n",
    "attn_dense1 = Dense(10, activation='tanh')\n",
    "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
    "\n",
    "attn_dot = Dot(axes=1) # to perform the weighted sum of alpha[t] * h[t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(h, st_1):\n",
    "  # h = h(1), ..., h(Tx), shape = (Tx, LATENT_DIM * 2)\n",
    "  # st_1 = s(t-1), shape = (LATENT_DIM_DECODER,)\n",
    " \n",
    "  # copy s(t-1) Tx times\n",
    "  # now shape = (Tx, LATENT_DIM_DECODER)\n",
    "  st_1 = attn_repeat_layer(st_1)\n",
    "\n",
    "  # Concatenate all h(t)'s with s(t-1)\n",
    "  # Now of shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n",
    "  x = attn_concat_layer([h, st_1])\n",
    "\n",
    "  # Neural net first layer\n",
    "  x = attn_dense1(x)\n",
    "\n",
    "  # Neural net second layer with special softmax over time\n",
    "  alphas = attn_dense2(x)\n",
    "\n",
    "  # \"Dot\" the alphas and the h's\n",
    "  # Remember a.dot(b) = sum over a[t] * b[t]\n",
    "  context = attn_dot([alphas, h])\n",
    "\n",
    "  return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the rest of the decoder (after attention)\n",
    "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "\n",
    "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
    "initial_c = Input(shape=(LATENT_DIM_DECODER,), name='c0')\n",
    "context_last_word_concat_layer = Concatenate(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s, c will be re-assigned in each iteration of the loop\n",
    "s = initial_s\n",
    "c = initial_c\n",
    "\n",
    "# collect outputs in a list at first\n",
    "outputs = []\n",
    "for t in range(max_len_target): # Ty times\n",
    "  # get the context using attention\n",
    "  context = one_step_attention(encoder_outputs, s)\n",
    "\n",
    "  # we need a different layer for each time step\n",
    "  selector = Lambda(lambda x: x[:, t:t+1])\n",
    "  xt = selector(decoder_inputs_x)\n",
    "  \n",
    "  # combine \n",
    "  decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
    "\n",
    "  # pass the combined [context, last word] into the LSTM\n",
    "  # along with [s, c]\n",
    "  # get the new [s, c] and output\n",
    "  o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
    "\n",
    "  # final dense layer to get next word prediction\n",
    "  decoder_outputs = decoder_dense(o)\n",
    "  outputs.append(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_and_transpose(x):\n",
    "  # x is a list of length T, each element is a batch_size x output_vocab_size tensor\n",
    "  x = K.stack(x) # is now T x batch_size x output_vocab_size tensor\n",
    "  x = K.permute_dimensions(x, pattern=(1, 0, 2)) # is now batch_size x T x output_vocab_size\n",
    "  return x\n",
    "\n",
    "# make it a layerx``\n",
    "stacker = Lambda(stack_and_transpose)\n",
    "outputs = stacker(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = Model(\n",
    "  inputs=[\n",
    "    encoder_inputs_placeholder,\n",
    "    decoder_inputs_placeholder,\n",
    "    initial_s, \n",
    "    initial_c,\n",
    "  ],\n",
    "  outputs=outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "# checkpoint\n",
    "filepath=\"french_eng_finalmodel\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# compile the model\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate) ,loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sinch\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\sinch\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/30\n",
      "32000/32000 [==============================] - 166s 5ms/step - loss: 3.5001 - accuracy: 0.2610 - val_loss: 2.7392 - val_accuracy: 0.3689\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.36892, saving model to french_eng_finalmodel\n",
      "Epoch 2/30\n",
      "32000/32000 [==============================] - 160s 5ms/step - loss: 2.3606 - accuracy: 0.4976 - val_loss: 2.0123 - val_accuracy: 0.5802\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.36892 to 0.58021, saving model to french_eng_finalmodel\n",
      "Epoch 3/30\n",
      "32000/32000 [==============================] - 160s 5ms/step - loss: 1.7014 - accuracy: 0.6247 - val_loss: 1.4083 - val_accuracy: 0.6718\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.58021 to 0.67181, saving model to french_eng_finalmodel\n",
      "Epoch 4/30\n",
      "32000/32000 [==============================] - 160s 5ms/step - loss: 1.2054 - accuracy: 0.7013 - val_loss: 1.0190 - val_accuracy: 0.7462\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67181 to 0.74623, saving model to french_eng_finalmodel\n",
      "Epoch 5/30\n",
      "32000/32000 [==============================] - 160s 5ms/step - loss: 0.9032 - accuracy: 0.7758 - val_loss: 0.7975 - val_accuracy: 0.7972\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.74623 to 0.79722, saving model to french_eng_finalmodel\n",
      "Epoch 6/30\n",
      "32000/32000 [==============================] - 160s 5ms/step - loss: 0.7359 - accuracy: 0.8076 - val_loss: 0.7053 - val_accuracy: 0.8087\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.79722 to 0.80866, saving model to french_eng_finalmodel\n",
      "Epoch 7/30\n",
      "32000/32000 [==============================] - 162s 5ms/step - loss: 0.6244 - accuracy: 0.8361 - val_loss: 0.5573 - val_accuracy: 0.8590\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.80866 to 0.85899, saving model to french_eng_finalmodel\n",
      "Epoch 8/30\n",
      "32000/32000 [==============================] - 159s 5ms/step - loss: 0.5006 - accuracy: 0.8782 - val_loss: 0.4395 - val_accuracy: 0.8958\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.85899 to 0.89583, saving model to french_eng_finalmodel\n",
      "Epoch 9/30\n",
      "32000/32000 [==============================] - 160s 5ms/step - loss: 0.3843 - accuracy: 0.9126 - val_loss: 0.3314 - val_accuracy: 0.9257\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.89583 to 0.92567, saving model to french_eng_finalmodel\n",
      "Epoch 10/30\n",
      "32000/32000 [==============================] - 160s 5ms/step - loss: 0.2844 - accuracy: 0.9378 - val_loss: 0.2433 - val_accuracy: 0.9484\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.92567 to 0.94843, saving model to french_eng_finalmodel\n",
      "Epoch 11/30\n",
      "32000/32000 [==============================] - 160s 5ms/step - loss: 0.2067 - accuracy: 0.9571 - val_loss: 0.1767 - val_accuracy: 0.9641\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.94843 to 0.96409, saving model to french_eng_finalmodel\n",
      "Epoch 12/30\n",
      "32000/32000 [==============================] - 160s 5ms/step - loss: 0.1464 - accuracy: 0.9697 - val_loss: 0.1247 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.96409 to 0.97217, saving model to french_eng_finalmodel\n",
      "Epoch 13/30\n",
      "32000/32000 [==============================] - 159s 5ms/step - loss: 0.1064 - accuracy: 0.9752 - val_loss: 0.0934 - val_accuracy: 0.9762\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.97217 to 0.97621, saving model to french_eng_finalmodel\n",
      "Epoch 14/30\n",
      "32000/32000 [==============================] - 159s 5ms/step - loss: 0.2066 - accuracy: 0.9443 - val_loss: 0.4684 - val_accuracy: 0.8739\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.97621\n",
      "Epoch 15/30\n",
      "32000/32000 [==============================] - 160s 5ms/step - loss: 0.2124 - accuracy: 0.9548 - val_loss: 0.1060 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.97621\n",
      "Epoch 16/30\n",
      "32000/32000 [==============================] - 166s 5ms/step - loss: 0.0868 - accuracy: 0.9764 - val_loss: 0.0760 - val_accuracy: 0.9766\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.97621 to 0.97656, saving model to french_eng_finalmodel\n",
      "Epoch 17/30\n",
      "32000/32000 [==============================] - 178s 6ms/step - loss: 0.0691 - accuracy: 0.9781 - val_loss: 0.0654 - val_accuracy: 0.9778\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.97656 to 0.97785, saving model to french_eng_finalmodel\n",
      "Epoch 18/30\n",
      "32000/32000 [==============================] - 175s 5ms/step - loss: 0.0609 - accuracy: 0.9790 - val_loss: 0.0590 - val_accuracy: 0.9788\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.97785 to 0.97878, saving model to french_eng_finalmodel\n",
      "Epoch 19/30\n",
      "32000/32000 [==============================] - 174s 5ms/step - loss: 0.0551 - accuracy: 0.9802 - val_loss: 0.0541 - val_accuracy: 0.9806\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.97878 to 0.98058, saving model to french_eng_finalmodel\n",
      "Epoch 20/30\n",
      "32000/32000 [==============================] - 174s 5ms/step - loss: 0.0506 - accuracy: 0.9815 - val_loss: 0.0501 - val_accuracy: 0.9815\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.98058 to 0.98151, saving model to french_eng_finalmodel\n",
      "Epoch 21/30\n",
      "32000/32000 [==============================] - 176s 5ms/step - loss: 0.0470 - accuracy: 0.9826 - val_loss: 0.0471 - val_accuracy: 0.9823\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.98151 to 0.98226, saving model to french_eng_finalmodel\n",
      "Epoch 22/30\n",
      "32000/32000 [==============================] - 176s 5ms/step - loss: 0.0439 - accuracy: 0.9835 - val_loss: 0.0442 - val_accuracy: 0.9827\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.98226 to 0.98273, saving model to french_eng_finalmodel\n",
      "Epoch 23/30\n",
      "32000/32000 [==============================] - 174s 5ms/step - loss: 0.0413 - accuracy: 0.9841 - val_loss: 0.0417 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.98273 to 0.98364, saving model to french_eng_finalmodel\n",
      "Epoch 24/30\n",
      "32000/32000 [==============================] - 162s 5ms/step - loss: 0.0392 - accuracy: 0.9844 - val_loss: 0.0402 - val_accuracy: 0.9833\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.98364\n",
      "Epoch 25/30\n",
      "32000/32000 [==============================] - 160s 5ms/step - loss: 0.0374 - accuracy: 0.9848 - val_loss: 0.0381 - val_accuracy: 0.9839\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.98364 to 0.98388, saving model to french_eng_finalmodel\n",
      "Epoch 26/30\n",
      "32000/32000 [==============================] - 159s 5ms/step - loss: 0.0357 - accuracy: 0.9850 - val_loss: 0.0366 - val_accuracy: 0.9841\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.98388 to 0.98411, saving model to french_eng_finalmodel\n",
      "Epoch 27/30\n",
      "32000/32000 [==============================] - 160s 5ms/step - loss: 0.0343 - accuracy: 0.9853 - val_loss: 0.0356 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.98411 to 0.98430, saving model to french_eng_finalmodel\n",
      "Epoch 28/30\n",
      "32000/32000 [==============================] - 163s 5ms/step - loss: 0.0331 - accuracy: 0.9855 - val_loss: 0.0343 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.98430 to 0.98436, saving model to french_eng_finalmodel\n",
      "Epoch 29/30\n",
      "32000/32000 [==============================] - 173s 5ms/step - loss: 0.0320 - accuracy: 0.9859 - val_loss: 0.0332 - val_accuracy: 0.9841\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.98436\n",
      "Epoch 30/30\n",
      "32000/32000 [==============================] - 171s 5ms/step - loss: 0.0310 - accuracy: 0.9861 - val_loss: 0.0325 - val_accuracy: 0.9843\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.98436\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "z = np.zeros((encoder_inputs.shape[0], LATENT_DIM_DECODER)) # initial [s, c]\n",
    "r = model.fit(\n",
    "  [encoder_inputs, decoder_inputs, z, z], decoder_targets_one_hot,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=0.2,\n",
    "    callbacks=callbacks_list\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot some data\n",
    "plt.plot(r.history['loss'], label='loss')\n",
    "plt.plot(r.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU5dn/8c+VyWQFQiAh7BAh7KtGXKsoqGgruKDiVtQqtXVv+1Rr/bn7PD6ta5XaB61rUUpRFFuqsop1JSzKDgEFQshC2BKyzsz1++MMIQlZBpgwmcn1fr3ymjn3nDlznYx8PbnPfe4jqooxxpjIEBXqAowxxgSPhboxxkQQC3VjjIkgFurGGBNBLNSNMSaCRIfqg1NSUrR3796h+nhjjAlLy5Yt26WqqQ29HrJQ7927N1lZWaH6eGOMCUsisrWx1637xRhjIkiToS4ir4pIgYisbuB1EZE/iUi2iHwnIicGv0xjjDGBCORI/XVgXCOvXwhk+H+mAC8de1nGGGOORpN96qq6RER6N7LKBOBNdeYb+EpE2otIF1XdeaTFVFVVkZOTQ3l5+ZG+tVWIi4uje/fuuN3uUJdijGmhgnGitBuwvcZyjr/tsFAXkSk4R/P07NnzsA3l5OTQtm1bevfujYgEobTIoaoUFRWRk5NDenp6qMsxxrRQwThRWl/61jtLmKpOU9VMVc1MTT18RE55eTkdO3a0QK+HiNCxY0f7K8YY06hghHoO0KPGcncg92g3ZoHeMPvdGGOaEozulznA7SIyAzgF2Hc0/enGmMjk8yk+VbyqqILXv+zzgVcPPlf/c2f96nX8baqgOO/3+bcDtdsVp5vSV2M7znv92/YpPvWhPh/qUxScZQXwP1Z/lq/6vaqCRxWvCgp4fFF4qb/O2rXVqF19qCqoD0UZM7ALw3t2aJbfd5OhLiLvAKOBFBHJAR4C3P6i/wLMBS4CsoFS4MZmqdSY1sznBW8leCvxVVVSUVlORXk5lRVlVFaUU1lZQVVlBVWV5XiqKvB5qvB6KvF5qvBVVeL1VqEe5xFvFeqpwuf1oD6PP+Q8qM+Lej2gXtTnBZ//Ub1E+Ty41INLq4iu+YjzGI0Ht3qIwosPwUcUXpXq54c9quASHy58ROMlCh/R+HDhJRovLnzEiPPo8r9LwL+FQ4+CIihRNR6p0yZAlAT/vhE+f8j7anxq9ecdrLOBz/1m/wPQ87+CXhMENvrl6iZeV+C2oFVkTAunPh8VFWWUlR6g9EAJlRWllJceoLK8lMryUjyVZfg8lajHCVf1VIC3EvVWgqcCvFXgrUS8lUR5yoj2lBLtLcXtLcPtLSXWV0aMr4w4LSNWy4nTcmKpqv78KCDe/xNMTrQe+lHxPxcXXonGK27nJyoab5Qbn/+5T+LxRbnxRbnxiMsf0IrbH6xReBGt8RxF1IdGuUBcqLjQqGiIcqES7W+PxhcVjTfKBRJ16AfxPxfnhxrPxXlNRBBxOS/jLBN1sF0QiXI2c7D3WcQ5MShS4z34zxZKrf9h1A5tJUrU/z8XJ9pFooAo1F+Pz/8o+B/9tY/KGBvkb++QkE0T0JJdcsklbN++nfLycu666y6mTJnCRx99xP3334/X6yUlJYUFCxZQUlLCHXfcQVZWFiLCQw89xOWXXx7q8sOX1wMl+VC8E/bn4tmXS3Hhdsp3b0f37aQyriM9bp6Oy+UKzueV7oZN86BiP1QUOz+VJYeeVxSjFcWUluylvGQfbl85MVpJnFQRB8QBycfw8T6EMmIpJ45yiaNc4qmIiqckqg2VMalURSVQFR2PNzoRnysOiY6B6BiiomOJio7F5Y7B5Y4l2h2Lyx2LKyYWt/+52x1DdI0fd0wM7hinPcYdS1R0NES5wR+sRLlwiRCk36wJoRYb6o98uIa1ufuDus1BXdvx0MWDm1zv1VdfpUOHDpSVlXHyySczYcIEbrnlFpYsWUJ6ejq7d+8G4LHHHiMpKYlVq1YBsGfPnqDWG7HK90PuCshdjnfHcqp2bUWKd+Iu30UUvurVooE26uIAyZRqLP2ivuGJ/3uV22+4gaSEIIzVn/cgrHjr0LK4ILYtxLaD2DaUSgKb9kWx/UAqEptOcnJ7iI5D3PGIO5YodzxRsQlEx8QTHZuAOzaemNgEomPjiI6Jw+WOwxUTg9sdS7TbaXPHxDrh7IolKspFogiJx74nxlRrsaEeSn/605+YPXs2ANu3b2fatGmcddZZ1ePDO3RwTnDMnz+fGTNmVL8vOflYjtsilKcC8lfDjuX+n2Xoro2If9TrDu3E977O5Okg8khmX3QK0q4rscndaNepJ506d6NXSlt6t4OqqYMZkPch46f2Zdr1mfTv3Pbo66oogdXvwdAr4YInnDCPjgMRCorLeXbeRv6+dDtt49zcdUEG153ai5homyrJtHwtNtQDOaJuDosXL2b+/Pl8+eWXJCQkMHr0aIYPH86GDRsOW1dVbZhhXT4f/LAE1v8LdiyDvFXOCT6gPKYjG1wZLPJOZLn3BHYmDOS0oRmc2DOZfh0TOL9jIsmJMQ1ve9jlXPLdLJ6vKOHSP3/O01cM58KhXY6uzrXvQ9UBOPlmaNPJqa/KyyufbeGlxZup8Pi48Yx07ji3L+0TGqnJmBamxYZ6qOzbt4/k5GQSEhJYv349X331FRUVFXz66ad8//331d0vHTp04Pzzz+fFF1/kueeeA5zul1Z7tF66G1ZOh6zXYPdmcCdS1XkEm3tdx/z93Zi5sxPbyjvQJSmeC0d14c6hnTmxZzJRUUfwP8UR1+Ja/iYfXlDEDSsy+MX05dx+Tl/uOa8friPZDsCKv0HHDOgxCp9PmfNtLn/4aD25+8q5YHAa9104kPQU6xgx4cdCvY5x48bxl7/8hWHDhtG/f39OPfVUUlNTmTZtGpdddhk+n49OnToxb948HnjgAW677TaGDBmCy+XioYce4rLLLgv1Lhw/qrD9a8h6Fda8D94KtMdpfNf3Vp7bMZAlm4vx+pTuyfFcdEYXLhzSmeHd2x9ZkNfU4xTo0Iek9f9gxpQ5PPTBGl5clM2a3H08N2kkSfEB9rPvyoZtX8LYR1i6dQ+P/3Mt3+bsY0i3djxz1QhOPaHj0dVnTAsgqsEfvxmIzMxMrXuTjHXr1jFw4MCQ1BMuWsTvqHw/fPd356i8YA3EtkOHXcXn7S/m8aXC+rxienSI5+JhXbloaBcGd20XvG6qJU/BwsfgzpVocm+mf72Nh+esoUeHBKZdfxIZaY33s1d4vBTOvp+ua17mhuTXWbLTRVq7WH57wQAuHdnt6P+HY8xxIiLLVDWzodftSN0Ebud3sPQVWDXL6Y/uMhzfT/7EgugzeebTXNbt3E96SiLPXjWci4d1JdrVDCcWh0+ChY/Dt+8g59zPdaf2ol9aW345fRmXTP2cZ64awQWDO1evrqpsLixhycZdfLapkKVbClkQNYPFOpzy2FTuv6gT153ai4QY+6dgIoP9l2yaVlIA8x92+syj42HoRDTzJj7Z25Xn529i7c71zR/mByV1hxNGw8p34Oz7ICqKUekd+PCOM7n1rWX8/K1l3HFuXzLS2vLZxkI+27SLvP3OJGgnpCRyX8YO0rbspd1ld3Hu8NOar05jQsRC3TTMWwXfTIPFT0JVGZxxF3rmPXyypYLnZ21i7c5lpKck8syVwxk/vJnDvKaR18G7P4Ot/4H0swDokhTP339+Gg+8v5oXFmYDkBTv5sy+KfwoI4UzM1LonpwAf/8rJKQQP/ii41OrMceZhbqp35ZP4d+/hcL10HcsjHuSBYXteObl1azJ3U/vjgnHP8wPGvBj5wKhlW9XhzpAnNvFHycO47KR3UiIjWZot6Tao2IO7IIN/4ZTfg7RNkzRRCYLdVPb3u3wye9h7QfQvhdMeoeCrufw4Adr+WjNRnp3TODpK4YzYUQIwvwgdzwMuQy+mwkX/dG5cMhPRDi9b0r97/tuJviqYMS1x6lQY44/C3XjqCqHL1+AJU8DCuf8Hj3tdt5btZtHn/2Msiov944bwC0/Sg9dmNc04jpY9rozlPLE65teX9UZm97tJEgb1OzlGRMqFuoGNnwEH90Le36AgePhgifIJZX7p69i8YZCTuqVzB8mDqNPaptQV3pI90zn4qGVbwcW6rkrnOGXP3m2+WszJoQs1I9BmzZtKCkpCXUZR6/yAHx4F6z6B6T0h+vfx5c+mneWbuN/5i7B61MeungQPz2t95FfsdncRGDENbDgESjaDB37NL7+ir85c7sMsVk0TWRrAX9Hm5DYtQleHgOr34Vzfg+/+Jyt7UdxzStf8fvZqxnWPYmP7z6LG89Ib3mBftDwSc7c2t++0/h6VWXO2PpBEyAu6fjUZkyItNwj9X/f50wGFUydh8KFTzb48r333kuvXr345S9/CcDDDz+MiLBkyRL27NlDVVUVjz/+OBMmTGjyo0pKSpgwYUK973vzzTd56qmnEBGGDRvGW2+9RX5+PrfeeitbtmwB4KWXXuL0008Pwk7XY8378MFtEB0L172HN300r33+PU99sgF3VBRPXjaUq07u0fInK2vXFfqc64xZH30/RDVwjLLun1CxzxkKaUyEa7mhHgKTJk3i7rvvrg71mTNn8tFHH3HPPffQrl07du3axamnnsr48eObDLy4uDhmz5592PvWrl3LE088weeff05KSkr13Ox33nknZ599NrNnz8br9TZPt463yrmI6MsXoVsmXPkGP1Qlc89fvmDFtr2MGdCJxy8dQpekYN9TpxmNuAZm3QTffwp9zql/nRVvQfue0OvM41ubMSHQckO9kSPq5jJy5EgKCgrIzc2lsLCQ5ORkunTpwj333MOSJUuIiopix44d5Ofn07lz50a3parcf//9h71v4cKFTJw4kZQUZ9jdwbnZFy5cyJtvvgmAy+UiKSnI3QTFefCPG2HbF3DyLXDBf7NyZyk3vf4FXp/y3FUjmDCia8s/Oq+r/4+dLpWVb9cf6nu2OoHf2JG8MREkoFAXkXHA84ALeEVVn6zzei/gVSAV2A1cp6o5Qa71uJg4cSKzZs0iLy+PSZMmMX36dAoLC1m2bBlut5vevXtTXl7e5HYael9I5mD/4XOYdaMzEddlL8OwK1m0voBfTl9OStsY3rhxFCe0pJEtR8IdB0MmOqFevu/wPvOVbwMCIxq91a4xEaPJQxcRcQFTgQuBQcDVIlJ3oO9TwJuqOgx4FPifYBd6vEyaNIkZM2Ywa9YsJk6cyL59++jUqRNut5tFixaxdevWgLbT0PvGjBnDzJkzKSoqAqjufhkzZgwvvfQSAF6vl/37g3ArP1X44gV442KIaQO3LIBhVzJz6XZufjOLPp0See8XZ4RvoB804lrwlMGa2bXbfT4n1E8Y7XS/GNMKBPL36CggW1W3qGolMAOoe6ZwELDA/3xRPa+HjcGDB1NcXEy3bt3o0qUL1157LVlZWWRmZjJ9+nQGDBgQ0HYaet/gwYP5/e9/z9lnn83w4cP51a9+BcDzzz/PokWLGDp0KCeddBJr1qw5th0p3w8zfwqfPAD9L4Qpi9BOg3hhwSZ+++53nN6nIzOmnEZq29hj+5yWoNuJzpDMlW/Xbv9hCezbZidITasSSPdLN2B7jeUc4JQ663wLXI7TRXMp0FZEOqpqUc2VRGQKMAWgZ8+We+R08EbSACkpKXz55Zf1rtfYyczG3jd58mQmT55cqy0tLY0PPvjgKKqtx74d8NalUJQN5z0Gp9+BV+HB91cz/ettXDqyG/97+bDIueemCIy81rmR9K5sSOnrtK/4m9MdM+Anoa3PmOMokH/V9XUA172zxm+As0VkBXA2sAPwHPYm1WmqmqmqmampqUdcrAnA7u/htXFQvBN++j6ccSflHh+/+Nsypn+9jVvP7sPTVwyPnEA/aNhVzpj1ldOd5bI9sHaOc2Npd1xoazPmOArkSD0H6FFjuTuQW3MFVc0FLgMQkTbA5aq6L1hFtmSrVq3i+utrX6YeGxvL119/ffyLKdwIb44HTzn89APodiJ7Syu5+Y0slm3bw8MXD+KGM9KPf13HQ9vOzmyS386Acx9wLqryVljXi2l1Agn1pUCGiKTjHIFPAq6puYKIpAC7VdUH/A5nJMxRCcnokGMwdOhQVq5ceVw+q9FbD+atgjcvcY5Wb/gXpA1mx94yJr/6DduKSnnx6hP58bAux6XOkBlxLfxjMmxZ7HS9pA2FLsNDXZUxx1WTf4Orqge4HfgYWAfMVNU1IvKoiIz3rzYa2CAiG4E04ImjKSYuLo6ioqLGw6uVUlWKioqIi6unKyFnGbz+E+cK0Rv/DWmDWZ+3n8v+/Dn5+8t546ZRkR/o4JwQjmvvzAeTu8I5Sg+jAwRjgqFF3Xi6qqqKnJycgMaBt0ZxcXF0794dt9t9qHHrFzD9SkjoAJM/hORerNu5n6v+70sSYqJ5/aaTGdC5XeiKPt7+9RtY+jK4YuDXG5zfizERJKxuPO12u0lPj9A+3+aweSG8cw207+H0obfryvbdpUx+9RsSYqL5x62n0aNDQqirPL5GXuuEev8LLdBNq9SiQt0cgfVznf7jlH5w/fvQJpVdJRVc/9evqfD4WmegA3QZARf8D2ScH+pKjAkJC/VwtPpdeG8KdB4G170LCR0oLq/ihte+IW9/OdNvPpV+aW2b3k4kEoHTfhnqKowJmQgbrNwKrJgO794M3Uc5XS4JHSiv8jLlzWWs31nMS9edxEm9kkNdpTEmRCzUw8m3M+CDX0L62XDdLIhrh9en3D1jJV9uKeKpK4ZzTv9Ooa7SGBNC1v0SLvJWObee6/0juHoGuONQVR54fzUfrcnjwZ8M4pKR3UJdpTEmxOxIPRyU73Mm54prDxNfrb7s/Zl5G3nnm23cdk4fbjrTRg0ZY+xIveVThQ9ud272cMM/oY3TvfLa59/zwsJsJp3cg9+c3z/ERRpjWgoL9Zbuq5dg3RxntsVezj1LP1i5g0c+XMsFg9N4/JIhYTWtgjGmeVn3S0u27WuY9/+cqWNPvwOAxRsK+PXMbzklvQPPTxpJtMu+QmPMIZYILdWBXfCPGyCpO0yYCiJ8sXkXv/jbcvqlteXlyZnEuV2hrtIY08JY90tL5PPCe7dAaRHcPA9vbBIvzt/E8ws2kp6SyBs3jaJdnLvp7RhjWh0L9ZZoyR+deV0ufp6CxP7c9crXfLmliMtGduOxS4aQGGtfmzGmfpYOLU32Alj8JAy/mk/bXMSvnv+M0kovT10xnIkndQ91dcaYFs5CvSXZlwPv3oymDuAZ98954bWl9E9ry9RrR9K3Uyudy8UYc0Qs1FsKTyX840Z8ngru9N7DP/+TyzWn9OTBnwyyE6LGmIBZqLcU8x+CnG/4LXezuKg9L1w9lIuHdw11VcaYMGOh3gJUrXoP91d/5jXPBWxIO49/XTOSXh0TQ12WMSYMBRTqIjIOeB5wAa+o6pN1Xu8JvAG0969zn6rODXKtkUMVdn4LGz+mct1cYvJXssLXlx0n/55ZPx5CbLR1txhjjk6ToS4iLmAqcB6QAywVkTmqurbGag/g3JD6JREZBMwFejdDveGrstS5y/3Gj2DTJ1C8E0VYTwaf6lUMueRuHjhxUKirNMaEuUCO1EcB2aq6BUBEZgATgJqhrsDBuxsnAbnBLDJs7d0Omz6GjR/D90vAUw4xbaHvuSyNGcUdS1OIbZ/GXydn2ugWY0xQBBLq3YDtNZZzgFPqrPMw8ImI3AEkAmPr25CITAGmAPTs2fNIaw0v/3kW5j/sPE9Oh8yboN8FeHucxpOfbOblz77njL4dmXrNibRPiAlpqcaYyBFIqNc3BaDWWb4aeF1VnxaR04C3RGSIqvpqvUl1GjANIDMzs+42IseWT2H+IzDwYhjzEHTsCyLsL6/irr+tYNGGQn56Wi/+308G4bYJuYwxQRRIqOcAPWosd+fw7pWfAeMAVPVLEYkDUoCCYBQZVorznXuIpmTAJX+B2DYA/LDrADe/mcUPuw7wxKVDuPaUXiEu1BgTiQI5TFwKZIhIuojEAJOAOXXW2QaMARCRgUAcUBjMQsOCzwvv/gwqiuHKN6sD/fPsXUyY+jm7Sip462enWKAbY5pNk0fqquoRkduBj3GGK76qqmtE5FEgS1XnAL8GXhaRe3C6Zm5Q1cjtXmnI4ifhh8/gkpeg00BUlbe+2sojH66lT2oir/z0ZHp2TAh1lcaYCBbQOHX/mPO5ddoerPF8LXBGcEsLM9kLnNkVR1wHI66hyuvjoTlrePvrbYwd2IlnrxpBW5su1xjTzOyK0mDYn+vMf95pIFz0R8C5KfTbX2/jF6P78Jvz++OKslvOGWOan4X6sfJ6YNZNUFUOV7wBMQkUFJfz2uffc8mIrtw7bkCoKzTGtCIW6sdq4WOw7Uu47BVI7QfAnxdtpsqr3D22X4iLM8a0NjZI+lhs/Bg+fw5OugGGXQHAjr1lvP31Nq44qTu9U2xSLmPM8WWhfrT2bofZP4fOQ2Hc/1Y3v7hwEwB3jMkIVWXGmFbMQv1oeCph1o1Of/oVb4A7DnAuMJqZlcM1p/SkW/v4EBdpjGmNrE/9aCx4BHKWwhWvQ8c+1c3PL9iE2yX8cnSfht9rjDHNyI7Uj9T6f8GXL8KoKTD40urmTfnFvL9yB5NP602ndnEhLNAY05pZqB+Jsr3wwW3QdSSc/3itl56dv5HEmGh+frYdpRtjQsdC/Uh88QKU7YHxL0B0bHXz6h37mLsqj5vOTKdDok2ja4wJHQv1QB3YBV+9BIMvc0a81PDMvI0kxbv52ZnpISrOGGMcFuqB+s+z4CmD0b+r1bxs6x4Wri9gylknkBRvc7sYY0LLQj0Q+3fC0ldg2KTqq0YPevqTDaS0ieGG03uHpjZjjKnBQj0Qnz0FPg+MvrdW8xfZu/hicxG/GN2XxFgbHWqMCT0L9abs2QrL3oATfwrJvaubVZWn522kc7s4rj0lwu+3aowJGxbqTfn0DyBRcNZ/1WpevLGQZVv3cPu5fYlzu0JUnDHG1Gah3phd2fDt23DyzdCua3WzqvL0JxvonhzPlZk9GtmAMcYcXxbqjVn83xAdD2feU6v54zV5rN6xn7vH9iMm2n6FxpiWI6BEEpFxIrJBRLJF5L56Xn9WRFb6fzaKyN7gl3qc5a2G1e/CqbdCm9TqZq9PeWbeRk5ITeSSEV0b2YAxxhx/TQ7ZEBEXMBU4D8gBlorIHP99SQFQ1XtqrH8HMLIZaj2+Fv03xCbB6XfUav7w21w25pfwwtUjiXbZUboxpmUJJJVGAdmqukVVK4EZwIRG1r8aeCcYxYXMjmWw4V9OoMcnVzd7vD6em7+RAZ3b8uOhXUJYoDHG1C+QUO8GbK+xnONvO4yI9ALSgYUNvD5FRLJEJKuwsPBIaz1+Fj4B8R2crpcaZq/YwQ9FpdxzXj+i7EbSxpgWKJBQry+9tIF1JwGzVNVb34uqOk1VM1U1MzU1tb5VQm/rF7B5gXNyNLZtdbPH6+PFRdkM7tqO8welhbBAY4xpWCChngPUHLfXHchtYN1JhHPXiyoseAzadHaGMdbw3oodbC0q5e6x/RCxo3RjTMsUSKgvBTJEJF1EYnCCe07dlUSkP5AMfBncEo+jzQth2xdw1m8gJqG6ucrr48WF2Qzp1o6xAzuFsEBjjGlck6Guqh7gduBjYB0wU1XXiMijIjK+xqpXAzNUtaGumZZNFRY+Dkk9nCkBapi9fAfbdpdy9xg7SjfGtGwBzUKlqnOBuXXaHqyz/HDwygqBDf+G3OUw/sVaN8Co8vp4YdEmhnZLYowdpRtjWjgbaA3g88GiJ6BDHxh+da2X3luew/bdZdw9NsOO0o0xLZ7NFwuw9n3IXw2X/xVch34llR4fLyzMZlj3JM4dYEfpxpiWz47UwblNXYc+MPjSWs3vLc8hZ48dpRtjwoeFeu5KyPnGGcIYdWgK3YNH6cO7J3FOfztKN8aEBwv1pS+DOwFGXFOr+d3lOezYW2bj0o0xYaV1h3rpblg1C4ZdCfHtq5srPc649OE92jO6fwu98tUYY+rRukN9xd/AUw4n31Kredayg0fp1pdujAkvrTfUfV5Y+gr0OgM6D6lurvT4mLoomxE92jO6nx2lG2PCS+sN9ez5sHfrYXO8zMzabkfpxpiw1XpD/ZtpzsRdAy+ubqrwePnzomxG9mzP2XaUbowJQ60z1Is2O0fqmTeBy13dPDMrh9x95dxjI16MMWGqdYb60r9CVDScNLm66eBR+ok92/OjjJQQFmeMMUev9YV65QFn1MugCdC2c3XzzKXb2bmvnHvOs6N0Y0z4an2hvuofULGv1jDGCo+XqYs2c1KvZM7sa0fpxpjw1bpCXRW+eRnShkLPU6ubZy/fQd5+60s3xoS/1hXq275yZmMcdQvUCO+5q/NIT0nkjL4dQ1icMcYcu9YV6t9Mg7gkGHpFdVNJhYevNhcxdmAnO0o3xoS91hPqxXmwbg6MvL7W/Uc/21hIpdfHmIFpISzOGGOCI6BQF5FxIrJBRLJF5L4G1rlSRNaKyBoReTu4ZQbBstfB53HGptcwb10+SfFuMnslh6YuY4wJoibvfCQiLmAqcB6QAywVkTmqurbGOhnA74AzVHWPiLSsCci9VZD1GvQ9Dzr2OdTsUxatL+DcAZ2IdrWeP1qMMZErkCQbBWSr6hZVrQRmABPqrHMLMFVV9wCoakFwyzxG6z6EkjwYNaVW8/Jte9hTWmU3lDbGRIxAQr0bsL3Gco6/raZ+QD8R+VxEvhKRccEqMCi+eRmSe0PfsbWa56/Lx+0SzrJ5XowxESKQUK9vSIjWWY4GMoDRwNXAKyLSvu6bRGSKiGSJSFZhYeGR1np08lbDti/8t6urvbvz1+ZzSnpH2sW5G3izMcaEl0BCPQfoUWO5O5BbzzofqGqVqn4PbMAJ+VpUdZqqZqpqZmrqcTo6XvoyRMfBiGtrNX+/6wCbCw8w1rpejDERJJBQXwpkiEi6iMQAk4A5ddZ5HzgHQERScLpjtgSz0KNSthe+m+mMS0/oUOulBevyAWwoozEmojQZ6qrqAW4HPgbWATNVdY2IPCoi4/2rfQwUichaYBHwX6pa1FxFB/EkBtQAAA5DSURBVGzl21BV6lxBWse8tfkM6NyWHh0S6nmjMcaEpyaHNAKo6lxgbp22B2s8V+BX/p+WI+uv0OMU6DK8VvPe0kqytu7hF2f3aeCNxhgTniJ3cHZJIRRlw8Dxh720eEMhXp/aUEZjTMSJ3FDPX+U8dh562Evz1+WT0iaW4d0PG6BjjDFhLYJDfY3zmDakVnOlx8enGwoZM6ATUVE2gZcxJrJEbqjnrYa2XSCx9nS633y/m+IKD2MH2agXY0zkidxQz1992FE6OF0vsdFRdocjY0xEisxQ91RC4QZIG1yrWVWZvy6fM/umEB/jClFxxhjTfCIz1HdtBF/VYSdJN+aXkLOnzLpejDERKzJDPX+181in+2X+watIB9hQRmNMZIrcUHfFQse+tZrnr8tnePckOrWLC1FhxhjTvCIz1PNWQ6cB4Dp0wWxhcQUrt++1uV6MMREtMkM9fw2k1e5PX7S+AFUYa6FujIlgkRfqJQVwoOCwkS/z1uXTNSmOgV3ahqgwY4xpfpEX6nkHpwc4dJK0vMrLZ5sKGTsoDRG7itQYE7kiL9TrmR7gi827KK/yWdeLMSbiRWCor4a2XWvdFGPe2gISY1ycckKHRt5ojDHhL/JCPW91ra4Xn09ZuD6fs/unEhttV5EaYyJbZIW6pxJ21Z4eYHXuPvL3VzBmgHW9GGMiX2SF+q4N4PPU6k+fv66AKIFz7CpSY0wrEFmhnuefHqDGnC/z1+ZzUq9kOiTGhKgoY4w5fgIKdREZJyIbRCRbRO6r5/UbRKRQRFb6f24OfqkBODg9QAfn3qO5e8tYu3O/jXoxxrQaTd54WkRcwFTgPCAHWCoic1R1bZ1V/66qtzdDjYHLXw2dBlZPD7DAP4GXzcpojGktAjlSHwVkq+oWVa0EZgATmreso6B62MiXeesKSE9JpE9qmxAWZowxx08god4N2F5jOcffVtflIvKdiMwSkR71bUhEpohIlohkFRYWHkW5jSgpgNJd1SdJPV4fX20pYnT/1OB+jjHGtGCBhHp919VrneUPgd6qOgyYD7xR34ZUdZqqZqpqZmpqkMM23z89gD/Ut+0updLjY3DXpOB+jjHGtGCBhHoOUPPIuzuQW3MFVS1S1Qr/4svAScEp7whUTw/gjFHfVFACQEYn63oxxrQegYT6UiBDRNJFJAaYBMypuYKIdKmxOB5YF7wSA5S3Gtp1q54eINsf6n0s1I0xrUiTo19U1SMitwMfAy7gVVVdIyKPAlmqOge4U0TGAx5gN3BDM9Zcv/zVtS46yi4ooWtSHG1im9xFY4yJGAElnqrOBebWaXuwxvPfAb8LbmlHwFPh3Gy637jqpk0FxfRNs7nTjTGtS2RcUVronx7AP5zR51OyC0roa0MZjTGtTGSEer5/egD/Lex27C2jvMpHRpqFujGmdYmQUF8D0XHQ4QTg0EnSvnaS1BjTykRGqOetqjU9wKaCYgDrfjHGtDrhH+qq9Y58SWkTS7LNzGiMaWXCP9RL8qG0qFaobyoooW+nxBAWZYwxoRH+oV49h7oT6qpKdn4JGZ1sOKMxpvUJ/1CvHvniTA9QUFxBcYXHRr4YY1qlyAj1dt0hPhmATfn+kS92ktQY0wqFf6jXmUM9++DIFztSN8a0QuEd6genB/B3vYBzkjQp3k1qm9gQFmaMMaER3qFeuB7UW8/IlzaI1DcNvDHGRLbwDvXqkS9Dq5s2F5TYHOrGmFYrvEM9fw1Ex1dPD1BUUkHRgUqbHsAY02qFeaj7pweIcgE254sxxoRvqKs63S81TpJmF/pvYWfzqBtjWqnwDfXiPCjbXas/fVN+CYkxLromxYWwMGOMCZ3wDfXqK0lrT+TVx0a+GGNasYBCXUTGicgGEckWkfsaWW+iiKiIZAavxAbkrXIe0wZVN2X7hzMaY0xr1WSoi4gLmApcCAwCrhaRQfWs1xa4E/g62EXWK38NJPWonh5gf3kVefvLbSIvY0yrFsiR+iggW1W3qGolMAOYUM96jwF/AMqDWF/D6plDHWzkizGmdQsk1LsB22ss5/jbqonISKCHqv6zsQ2JyBQRyRKRrMLCwiMutlpVOezaVHvkiz/U7cIjY0xrFkio13fWUatfFIkCngV+3dSGVHWaqmaqamZqamrgVdZ1cHqAzrWP1GOio+jRIeHot2uMMWEukFDPAXrUWO4O5NZYbgsMARaLyA/AqcCcZj1ZWj3ypeZwxmJOSEnEFWUjX4wxrVcgob4UyBCRdBGJASYBcw6+qKr7VDVFVXuram/gK2C8qmY1S8VQY3qA9Oqm7MISu+jIGNPqNRnqquoBbgc+BtYBM1V1jYg8KiLjm7vAeuWtcoYy+qcHKK30kLOnzPrTjTGtXnQgK6nqXGBunbYHG1h39LGX1WgxTvfLwIurm7YUHkDVRr4YY0z4XVFavBPK9tTqT7eRL8YY4wi/UK+eQ73mjTGKcUUJvTomhqgoY4xpGcIv1PP90wN0OnRR66b8Enp3TCAmOvx2xxhjgimgPvUWZcR10GU4xLevbsouLKGfTQ9gjDFheKTeNg36jq1erPB42VpUaidJjTGGcAz1On7YVYrXp2SkWagbY0zYh7pN5GWMMYeEfahvKihGBPqkWqgbY0zYh3p2QQk9khOIc7tCXYoxxoRcRIS6XXRkjDGOsA51j9fHlsID1p9ujDF+YR3q2/eUUen1WagbY4xfWIf6pvxiAJty1xhj/MI71P3DGfuk2pwvxhgDYR7qmwtK6JIUR9s4d6hLMcaYFiGsQ31TQYn1pxtjTA1hG+o+n5JtoW6MMbWEbajn7iujrMpLhs3OaIwx1QIKdREZJyIbRCRbRO6r5/VbRWSViKwUkf+IyKD6thNMB0+S2kRexhhzSJOhLiIuYCpwITAIuLqe0H5bVYeq6gjgD8AzQa+0jux8/0ReNueLMcZUC+RIfRSQrapbVLUSmAFMqLmCqu6vsZgIaPBKrF92QQkpbWJIToxp7o8yxpiwEcidj7oB22ss5wCn1F1JRG4DfgXEAOfWtyERmQJMAejZs+eR1lrLpoJiO0lqjDF1BHKkLvW0HXYkrqpTVbUPcC/wQH0bUtVpqpqpqpmpqalHVmnt7dhwRmOMqUcgoZ4D9Kix3B3IbWT9GcAlx1JUUwqLKygu99jIF2OMqSOQUF8KZIhIuojEAJOAOTVXEJGMGos/BjYFr8TDVY98sSN1Y4yppck+dVX1iMjtwMeAC3hVVdeIyKNAlqrOAW4XkbFAFbAHmNycRR+cyMu6X4wxprZATpSiqnOBuXXaHqzx/K4g19Wo7MIS2sVFk9o29nh+rDHGtHhheUXppvwSMtLaIlLfOVxjjGm9wjLUswtK7KIjY4ypR9iF+u4DlRQdqLTpAYwxph5hF+rZB2+MYSdJjTHmMGEX6psK/Lews1A3xpjDhF2op7aJ5bxBaXRNig91KcYY0+IENKSxJTl/cGfOH9w51GUYY0yLFHZH6sYYYxpmoW6MMRHEQt0YYyKIhboxxkQQC3VjjIkgFurGGBNBLNSNMSaCWKgbY0wEEdXDbjd6fD5YpBDYepRvTwF2BbGcliDS9inS9gcib58ibX8g8vapvv3ppaoN3uQ5ZKF+LEQkS1UzQ11HMEXaPkXa/kDk7VOk7Q9E3j4dzf5Y94sxxkQQC3VjjIkg4Rrq00JdQDOItH2KtP2ByNunSNsfiLx9OuL9Ccs+dWOMMfUL1yN1Y4wx9bBQN8aYCBJ2oS4i40Rkg4hki8h9oa7nWInIDyKySkRWikhWqOs5GiLyqogUiMjqGm0dRGSeiGzyPyaHssYj0cD+PCwiO/zf00oRuSiUNR4pEekhIotEZJ2IrBGRu/ztYfk9NbI/Yfs9iUiciHwjIt/69+kRf3u6iHzt/47+LiIxjW4nnPrURcQFbATOA3KApcDVqro2pIUdAxH5AchU1bC9YEJEzgJKgDdVdYi/7Q/AblV90v8/32RVvTeUdQaqgf15GChR1adCWdvREpEuQBdVXS4ibYFlwCXADYTh99TI/lxJmH5PIiJAoqqWiIgb+A9wF/Ar4D1VnSEifwG+VdWXGtpOuB2pjwKyVXWLqlYCM4AJIa6p1VPVJcDuOs0TgDf8z9/A+QcXFhrYn7CmqjtVdbn/eTGwDuhGmH5PjexP2FJHiX/R7f9R4Fxglr+9ye8o3EK9G7C9xnIOYf5F4nxpn4jIMhGZEupigihNVXeC8w8Q6BTieoLhdhH5zt89ExbdFPURkd7ASOBrIuB7qrM/EMbfk4i4RGQlUADMAzYDe1XV41+lycwLt1CXetrCp/+ofmeo6onAhcBt/j/9TcvzEtAHGAHsBJ4ObTlHR0TaAO8Cd6vq/lDXc6zq2Z+w/p5U1auqI4DuOD0TA+tbrbFthFuo5wA9aix3B3JDVEtQqGqu/7EAmI3zRUaCfH+/58H+z4IQ13NMVDXf/w/OB7xMGH5P/n7ad4Hpqvqevzlsv6f69icSvicAVd0LLAZOBdqLSLT/pSYzL9xCfSmQ4T8bHANMAuaEuKajJiKJ/pM8iEgicD6wuvF3hY05wGT/88nAByGs5ZgdDD6/Swmz78l/Eu6vwDpVfabGS2H5PTW0P+H8PYlIqoi09z+PB8binCtYBEz0r9bkdxRWo18A/EOUngNcwKuq+kSISzpqInICztE5QDTwdjjuj4i8A4zGmSY0H3gIeB+YCfQEtgFXqGpYnHxsYH9G4/xJr8APwM8P9kWHAxE5E/gMWAX4/M334/RDh9331Mj+XE2Yfk8iMgznRKgL54B7pqo+6s+JGUAHYAVwnapWNLidcAt1Y4wxDQu37hdjjDGNsFA3xpgIYqFujDERxELdGGMiiIW6McZEEAt1Y4yJIBbqxhgTQf4/zeFFqwMH4BMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracies\n",
    "plt.plot(r.history['accuracy'], label='acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the model for Predictions\n",
    "While training, we know the actual inputs to the decoder for all the output words in the sequence. However, during predictions the next word will be predicted on the basis of the previous word, which in turn is also predicted in the previous time-step. \n",
    "\n",
    "While making actual predictions, the full output sequence is not available, in fact that is what we have to predict. During prediction the only start and end token is avaialbale to us. We will use this to predict the output sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)\n",
    "\n",
    "# next we define a T=1 decoder model\n",
    "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM * 2,))\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "# no need to loop over attention steps this time because there is only one step\n",
    "context = one_step_attention(encoder_outputs_as_input, initial_s)\n",
    "\n",
    "# combine context with last word\n",
    "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])\n",
    "\n",
    "# lstm and final dense\n",
    "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
    "decoder_outputs = decoder_dense(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "decoder_model = Model(\n",
    "  inputs=[\n",
    "    decoder_inputs_single,\n",
    "    encoder_outputs_as_input,\n",
    "    initial_s, \n",
    "    initial_c\n",
    "  ],\n",
    "  outputs=[decoder_outputs, s, c]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions\n",
    "\n",
    "In the tokenization steps, we converted words to integers. The outputs from the decoder will also be integers. However, we want our output to be a sequence of words in the French language. To do so, we need to convert the integers back to words. We will create new dictionaries for both inputs and outputs where the keys will be the integers and the corresponding values will be the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decode_sequence() method will accept an input-padded sequence french sentence (in the integer form) and will return the translated english sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "  # Encode the input as state vectors.\n",
    "  enc_out = encoder_model.predict(input_seq)\n",
    "\n",
    "  # Generate empty target sequence of length 1.\n",
    "  target_seq = np.zeros((1, 1))\n",
    "  \n",
    "  # Populate the first character of target sequence with the start character.\n",
    "  # NOTE: tokenizer lower-cases all words\n",
    "  target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "  # if we get this we break\n",
    "  eos = word2idx_outputs['<eos>']\n",
    "\n",
    "\n",
    "  # [s, c] will be updated in each loop iteration\n",
    "  s = np.zeros((1, LATENT_DIM_DECODER))\n",
    "  c = np.zeros((1, LATENT_DIM_DECODER))\n",
    "\n",
    "\n",
    "  # Create the translation\n",
    "  output_sentence = []\n",
    "  for _ in range(max_len_target):\n",
    "    o, s, c = decoder_model.predict([target_seq, enc_out, s, c])\n",
    "        \n",
    "\n",
    "    # Get next word\n",
    "    idx = np.argmax(o.flatten())\n",
    "\n",
    "    # End sentence of EOS\n",
    "    if eos == idx:\n",
    "      break\n",
    "\n",
    "    word = ''\n",
    "    if idx > 0:\n",
    "      word = idx2word_trans[idx]\n",
    "      output_sentence.append(word)\n",
    "\n",
    "    # Update the decoder input\n",
    "    # which is just the word just generated\n",
    "    target_seq[0, 0] = idx\n",
    "\n",
    "  return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "To test the model, we use the french sentences from the test set, retrieve the corresponding padded sequence for the sentence, and will pass it to the decode_sequence() method. The method will return the translated sentence as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actual_sentence=[]\n",
    "test_predicted_sentence=[]\n",
    "for i in range(len(fr_test)):\n",
    "    # Do some test translations\n",
    "  \n",
    "  input_seq = encoder_inputs_test[i:i+1]\n",
    "  translation = decode_sequence(input_seq)\n",
    "\n",
    "  test_actual_sentence.append(target_texts_test[i])\n",
    "  test_predicted_sentence.append(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: france est calme en novembre , mais il est généralement agréable en juillet .\n",
      "\n",
      "Predicted translation: france is quiet during november , but it is usually nice in july .\n",
      "\n",
      "Actual translation: france is quiet during november , but it is usually nice in july .\n",
      " <eos>\n",
      "-\n",
      "Input sentence: ils pourraient se rendre à paris au printemps prochain .\n",
      "\n",
      "Predicted translation: they might go to paris next spring .\n",
      "\n",
      "Actual translation: they might go to paris next spring .\n",
      " <eos>\n",
      "-\n",
      "Input sentence: new jersey est jamais pluvieux au cours de l' automne , et il est parfois doux en juillet .\n",
      "\n",
      "Predicted translation: new jersey is never rainy during autumn , and it is sometimes mild in july .\n",
      "\n",
      "Actual translation: new jersey is never rainy during fall , and it is sometimes mild in july .\n",
      " <eos>\n",
      "-\n",
      "Input sentence: la banane est son fruit préféré moins , mais le raisin est son moins préféré .\n",
      "\n",
      "Predicted translation: the banana is his least favorite fruit , but the grape is her least favorite .\n",
      "\n",
      "Actual translation: the banana is his least favorite fruit , but the grape is her least favorite .\n",
      " <eos>\n",
      "-\n",
      "Input sentence: chine est généralement agréable en été , mais jamais à sec en octobre .\n",
      "\n",
      "Predicted translation: china is usually nice during summer , but it is never dry in october .\n",
      "\n",
      "Actual translation: china is usually nice during summer , but it is never dry in october .\n",
      " <eos>\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.randint(0,10000,5):\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts_test[i])\n",
    "    print('Predicted translation:', test_predicted_sentence[i])\n",
    "    print('Actual translation:', target_texts_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metric: BLEU Score\n",
    "\n",
    "BLEU, or the Bilingual Evaluation Understudy, is a score for comparing a candidate translation of text to one or more reference translations. NLTK also provides a function called corpus_bleu() for calculating the BLEU score for multiple sentences such as a paragraph or a document.\n",
    "\n",
    "The references must be specified as a list of sentences where each sentence is a list of references and each alternative reference is a list of tokens, e.g. a list of lists of lists of tokens. The candidate sentences must be specified as a list where each sentence is a list of tokens\n",
    "\n",
    "Here we will be passing predicted translations as list of candidate sentences and actual sentences as list of reference sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "pred=[]\n",
    "for words in test_predicted_sentence:\n",
    "    pred.append(words.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=[]\n",
    "for words in test_actual_sentence:\n",
    "    actual.append(words.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3300595072757995\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "chencherry = SmoothingFunction()\n",
    "BLEUscore = nltk.translate.bleu_score.corpus_bleu(actual,pred,smoothing_function=chencherry.method4)\n",
    "print(BLEUscore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
